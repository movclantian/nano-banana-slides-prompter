# LLM Configuration
# Supports any OpenAI-compatible API (OpenAI, OpenRouter, Ollama, LM Studio, etc.)
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=gpt-4o
OPENAI_MAX_TOKENS=16384    # Default increased to 16K
OPENAI_TEMPERATURE=0.7     # Configurable creativity

# Server Configuration
PORT=3001

# Frontend Configuration (optional - uses Vite proxy by default)
# VITE_API_BASE=http://localhost:3001
